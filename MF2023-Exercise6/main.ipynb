{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import MSELoss, L1Loss\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import torchvision\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import Compose, RandomCrop, ColorJitter, Resize\n",
    "from torchvision.io import write_png\n",
    "\n",
    "from pytorch_msssim import SSIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # Use GPU\n",
    "else:\n",
    "    device = torch.device(\"cpu\")  # Use CPU\n",
    "\n",
    "# Print the device being used\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define class SRDataset\n",
    "class SRDataset(Dataset):\n",
    "    def __init__(self, folder_path, augment):\n",
    "        self.folder_path = folder_path\n",
    "        self.image_filenames = os.listdir(folder_path)\n",
    "        self.t_crop = Compose([RandomCrop(64)])\n",
    "        self.t_colorjitter = Compose([ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2)])\n",
    "        self.t_downscale = Compose([Resize((32, 32), interpolation=torchvision.transforms.InterpolationMode.BILINEAR, antialias=True)])\n",
    "        self.augment = augment\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image_path = os.path.join(self.folder_path, self.image_filenames[index])\n",
    "        hr_image = self.t_crop(read_image(image_path) / 255.0)  # Convert to float between 0 and 1\n",
    "        if(self.augment):\n",
    "            lr_image = self.t_downscale(self.t_colorjitter(hr_image))\n",
    "        else:\n",
    "            lr_image = self.t_downscale(hr_image)\n",
    "        \n",
    "        return lr_image, hr_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define Model\n",
    "# class BasicSRModel(nn.Module):\n",
    "#     def __init__(self, num_inter_blocks):\n",
    "#         super(BasicSRModel, self).__init__()\n",
    "        \n",
    "#         self.conv_blocks = nn.Sequential(nn.ConvTranspose2d(3, 64, kernel_size=4, stride=2, padding=1))\n",
    "            \n",
    "#         for i in range(num_inter_blocks):  # Number of intermediate blocks\n",
    "#             self.conv_blocks.add_module(\n",
    "#                 f\"conv_{i+1}\",\n",
    "#                 nn.Sequential(\n",
    "#                     nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "#                     nn.LeakyReLU(inplace=True),\n",
    "#                 )\n",
    "#             )\n",
    "        \n",
    "#         self.conv_blocks.add_module(\n",
    "#             \"last_conv\",\n",
    "#             nn.Conv2d(64, 3, kernel_size=3, stride=1, padding=1)\n",
    "#         )\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         x = self.conv_blocks(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model\n",
    "class BasicSRModel(nn.Module):\n",
    "    def __init__(self, num_inter_blocks):\n",
    "        super(BasicSRModel, self).__init__()\n",
    "        \n",
    "        self.conv_blocks = nn.Sequential(nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False))\n",
    "        self.conv_blocks.add_module(\n",
    "            \"first_conv\",\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
    "        )\n",
    "\n",
    "\n",
    "        #self.conv_blocks = nn.Sequential(nn.ConvTranspose2d(3, 64, kernel_size=4, stride=2, padding=1))\n",
    "            \n",
    "        for i in range(num_inter_blocks):  # Number of intermediate blocks\n",
    "            self.conv_blocks.add_module(\n",
    "                f\"conv_{i+1}\",\n",
    "                nn.Sequential(\n",
    "                    nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "                    nn.LeakyReLU(inplace=True),\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        self.conv_blocks.add_module(\n",
    "            \"last_conv\",\n",
    "            nn.Conv2d(64, 3, kernel_size=3, stride=1, padding=1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_blocks(x)\n",
    "        return x\n",
    "    \n",
    "# Create an instance of BasicSRModel\n",
    "model = BasicSRModel(10)\n",
    "\n",
    "# Count the number of parameters\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(num_params)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING & EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and initialize the train_dataset\n",
    "train_datapath = os.path.join(os.path.abspath(''), 'data/train')\n",
    "train_dataset = SRDataset(train_datapath, augment=True)\n",
    "train_batch_size = 4\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=train_batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    drop_last=True,\n",
    "    pin_memory=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and initialize the test_dataset\n",
    "test_datapath = os.path.join(os.path.abspath(''), 'data/eval')\n",
    "test_dataset = SRDataset(test_datapath, augment=False)\n",
    "test_batch_size = 9\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=test_batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    drop_last=True,\n",
    "    pin_memory=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check Dataset initialization\n",
    "# print(f\" * Dataset contains {len(train_dataset)} image(s).\")\n",
    "# for _, batch in enumerate(train_dataloader, 0):\n",
    "#     lr_image, hr_image = batch\n",
    "#     write_png(lr_image[0, ...].mul(255).byte(), \"image-outputs/lr_image.png\")\n",
    "#     write_png(hr_image[0, ...].mul(255).byte(), \"image-outputs/hr_image.png\")\n",
    "#     break # we deliberately break after one batch as this is just a test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of BasicSRModel\n",
    "model.to(device)\n",
    "\n",
    "# Define optimizer\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()),lr=learning_rate)\n",
    "\n",
    "# Define loss function\n",
    "loss_function = L1Loss()\n",
    "loss_function.to(device)\n",
    "\n",
    "# # Print the model architecture\n",
    "# print(model)\n",
    "\n",
    "# # Check number of parameters in model\n",
    "num_params = 0\n",
    "for param in model.parameters():\n",
    "    num_params += param.numel()\n",
    "print(\"num_params: \" + str(num_params))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()\n",
    "number_of_epochs = 500\n",
    "for epoch in range(number_of_epochs):\n",
    "    with tqdm(train_dataloader, desc=f'Epoch {epoch + 1}/{number_of_epochs}', unit='batch') as tqdm_train_dataloader:\n",
    "        # TRAIN BATCH\n",
    "        cum_loss = 0\n",
    "        for _, (lr_image, hr_image) in enumerate(tqdm_train_dataloader):\n",
    "            lr_image, hr_image = lr_image.to(device), hr_image.to(device)\n",
    "            # reset the gradient\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass through the model\n",
    "            hr_prediction = model(lr_image)  \n",
    "            # compute the loss\n",
    "            loss = loss_function(hr_prediction, hr_image)\n",
    "            # backpropagation\n",
    "            loss.backward()\n",
    "            # update the model parameters\n",
    "            optimizer.step()\n",
    "            # add loss to be displayed at the end of epoch\n",
    "            cum_loss += loss.item()\n",
    "        # log training loss\n",
    "        writer.add_scalar('loss/train', cum_loss / train_batch_size, epoch)\n",
    "\n",
    "\n",
    "        # EVALUATE BATCH\n",
    "        cum_l1 = 0.0\n",
    "        cum_psnr = 0.0\n",
    "        cum_ssim = 0.0\n",
    "        with torch.no_grad():\n",
    "            for _, (lr_image, hr_image) in enumerate(test_dataloader):\n",
    "                lr_image, hr_image = lr_image.to(device), hr_image.to(device)\n",
    "                hr_prediction = model(lr_image)\n",
    "                # L1\n",
    "                l1_metric = L1Loss()\n",
    "                l1_metric.to(device)\n",
    "                l1_i = l1_metric(hr_prediction, hr_image)\n",
    "                # PSNR\n",
    "                mse_metric = MSELoss()\n",
    "                mse_metric.to(device)\n",
    "                psnr_i = -10 * torch.log10(mse_metric(hr_prediction, hr_image))\n",
    "                # SSIM\n",
    "                ssim_metric = SSIM(data_range=1.0)\n",
    "                ssim_metric.to(device)\n",
    "                ssim_i = ssim_metric(hr_prediction, hr_image)\n",
    "                # accumulate metrics\n",
    "                cum_psnr += psnr_i.item()\n",
    "                cum_ssim += ssim_i.item() \n",
    "                cum_l1 +=  l1_i.item()\n",
    "            # Log test loss\n",
    "            writer.add_scalar('loss/test-l1', cum_l1 / test_batch_size, epoch)   \n",
    "            writer.add_scalar('loss/test-psnr', cum_psnr / test_batch_size, epoch)\n",
    "            writer.add_scalar('loss/test-ssim', cum_ssim / test_batch_size, epoch)   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "torch.save(model.state_dict(), \"saved-models/modelv2-500.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Load model\n",
    "# model = BasicSRModel(10)\n",
    "# model.load_state_dict(torch.load(\"saved-models/model-upscale-first-500.pt\"))\n",
    "# model.to(device); # Suppress output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for _, (lr_image, hr_image) in enumerate(test_dataloader):\n",
    "        lr_image, hr_image = lr_image.to(device), hr_image.to(device)\n",
    "        hr_prediction = model(lr_image)\n",
    "        # Display images\n",
    "        lr_image_disp = lr_image.to('cpu')\n",
    "        hr_image_disp = hr_image.to('cpu')\n",
    "        hr_prediction_disp = hr_prediction.to('cpu')\n",
    "        write_png(lr_image_disp[0, ...].mul(255).byte(), \"image-outputs/lr_image.png\")\n",
    "        write_png(hr_image_disp[0, ...].mul(255).byte(), \"image-outputs/hr_image.png\")\n",
    "        write_png(hr_prediction_disp[0, ...].mul(255).byte(), \"image-outputs/hr_prediction.png\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
